[
  {
    "date": "2024-11-07",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-07",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-07",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-08",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-08",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-09",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-10",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-11",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-12",
    "total_citations": 202,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 157,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-13",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-14",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-15",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-16",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-17",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 164,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-18",
    "total_citations": 216,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-19",
    "total_citations": 219,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-20",
    "total_citations": 219,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-20",
    "total_citations": 219,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-21",
    "total_citations": 217,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-22",
    "total_citations": 217,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-23",
    "total_citations": 217,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-24",
    "total_citations": 217,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-25",
    "total_citations": 218,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-26",
    "total_citations": 219,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-27",
    "total_citations": 219,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-28",
    "total_citations": 221,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-29",
    "total_citations": 223,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-30",
    "total_citations": 223,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-01",
    "total_citations": 222,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-02",
    "total_citations": 223,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 167,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-03",
    "total_citations": 223,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 167,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-04",
    "total_citations": 223,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 167,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-05",
    "total_citations": 223,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 167,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-06",
    "total_citations": 224,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 168,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-07",
    "total_citations": 224,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 168,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-08",
    "total_citations": 224,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 168,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-09",
    "total_citations": 224,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 168,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-10",
    "total_citations": 224,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 168,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-11",
    "total_citations": 224,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 168,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-12",
    "total_citations": 224,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 168,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-13",
    "total_citations": 224,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 168,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-14",
    "total_citations": 226,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 170,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 18,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-15",
    "total_citations": 228,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 170,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 19,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-16",
    "total_citations": 229,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 170,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 20,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-17",
    "total_citations": 229,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 170,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 20,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-18",
    "total_citations": 229,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 170,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 20,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 15,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-19",
    "total_citations": 232,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 171,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 21,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-20",
    "total_citations": 233,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 172,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 21,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-21",
    "total_citations": 234,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 172,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 22,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-22",
    "total_citations": 235,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 172,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 22,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-23",
    "total_citations": 237,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 173,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 22,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-24",
    "total_citations": 238,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 174,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 22,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-12-25",
    "total_citations": 238,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 174,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 22,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 4,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  }
]