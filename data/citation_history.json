[
  {
    "date": "2024-11-07",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-07",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-07",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-08",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-08",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-09",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-10",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-11",
    "total_citations": 201,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 156,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-12",
    "total_citations": 202,
    "h_index": 5,
    "papers": [
      {
        "title": "Active Prompting with Chain-of-Thought for Large Language Models",
        "citations": 157,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric From Scratch for Large Language Models",
        "citations": 11,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt Learning using Metaheuristic",
        "citations": 8,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-13",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-14",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-15",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-16",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-17",
    "total_citations": 215,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 164,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 13,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-18",
    "total_citations": 216,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 165,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 16,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-19",
    "total_citations": 219,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  },
  {
    "date": "2024-11-20",
    "total_citations": 219,
    "h_index": 5,
    "papers": [
      {
        "title": "Active prompting with chain-of-thought for large language models",
        "citations": 166,
        "year": "2023"
      },
      {
        "title": "LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning",
        "citations": 17,
        "year": "2024"
      },
      {
        "title": "Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models",
        "citations": 14,
        "year": "2024"
      },
      {
        "title": "Plum: Prompt learning using metaheuristic",
        "citations": 9,
        "year": "2023"
      },
      {
        "title": "Dissecting the Runtime Performance of the Training, Fine-tuning, and Inference of Large Language Models",
        "citations": 7,
        "year": "2023"
      },
      {
        "title": "ParZC: Parametric Zero-Cost Proxies for Efficient NAS",
        "citations": 3,
        "year": "2024"
      },
      {
        "title": "LongGenBench: Long-context Generation Benchmark",
        "citations": 2,
        "year": "2024"
      },
      {
        "title": "Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models",
        "citations": 1,
        "year": "2024"
      },
      {
        "title": "Should We Really Edit Language Models? On the Evaluation of Edited Language Models",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "LPZero: Language Model Zero-cost Proxy Search from Zero",
        "citations": 0,
        "year": "2024"
      },
      {
        "title": "3D Question Answering for City Scene Understanding",
        "citations": 0,
        "year": "2024"
      }
    ]
  }
]