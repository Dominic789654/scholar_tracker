# Citation Statistics Overview

## Latest Statistics
*Last Updated: 2026-01-25*

### Quick Summary
| Metric | Value |
| ------ | ----- |
| Total Citations | 810 |
| H-index | 0 |
| Total Papers | 28 |
| Recent Citation Growth | +21 |

### Today's Changes
- Total Citations Increase: +21
- Papers with new citations:
  - Active prompting with chain-of-thought for large language models: +5 citations
  - LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning: +1 citations
  - Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models: +2 citations
  - Discovering Sparsity Allocation for Layer-wise Pruning of Large Language Models: +3 citations
  - LongGenBench: Long-context Generation Benchmark: +1 citations
  - Plum: Prompt Learning Using Metaheuristics: +1 citations
  - ParZC: Parametric Zero-Cost Proxies for Efficient NAS: +1 citations
  - ChunkKV: Semantic-preserving kv cache compression for efficient long-context llm inference: +2 citations
  - Should We Really Edit Language Models? On the Evaluation of Edited Language Models: +1 citations
  - Can LLMs Maintain Fundamental Abilities under KV Cache Compression?: +1 citations
  - Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression: +1 citations
  - Mediator: Memory-efficient llm merging with less parameter conflicts and uncertainty based routing: +1 citations
  - OracleKV: Oracle Guidance for Question-Independent KV Cache Compression: +1 citations