# Citation Statistics Overview

## Latest Statistics
*Last Updated: 2026-02-14*

### Quick Summary
| Metric | Value |
| ------ | ----- |
| Total Citations | 862 |
| H-index | 12 |
| Total Papers | 30 |
| Recent Citation Growth | +26 |

### Today's Changes
- Total Citations Increase: +26
- Papers with new citations:
  - Active prompting with chain-of-thought for large language models: +4 citations
  - LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning: +3 citations
  - Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models: +5 citations
  - LongGenBench: Long-context Generation Benchmark: +2 citations
  - Plum: Prompt Learning Using Metaheuristics: +1 citations
  - ChunkKV: Semantic-preserving kv cache compression for efficient long-context llm inference: +1 citations
  - Can LLMs Maintain Fundamental Abilities under KV Cache Compression?: +2 citations
  - Mediator: Memory-efficient llm merging with less parameter conflicts and uncertainty based routing: +3 citations
  - Can Compressed LLMs Truly Act? An Empirical Evaluation of Agentic Capabilities in LLM Compression: +1 citations
  - LPZero: Language Model Zero-cost Proxy Search from Zero: +1 citations
  - DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference: +1 citations
  - AnTKV: Anchor Token-Aware Sub-Bit Vector Quantization for KV Cache in Large Language Models: +1 citations
  - FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management: +1 citations